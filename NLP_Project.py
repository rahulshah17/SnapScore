# -*- coding: utf-8 -*-
"""NLP_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yk3vxl7OOa42bqviGGBRH17r3t3TFs1p
"""

!pip install customtkinter
!pip install diffusers

import tkinter as tk
import customtkinter as ctk
from PIL import ImageTk
import torch
from torch import autocast
from diffusers import StableDiffusionPipeline
from IPython.display import Image, display

ctk.set_appearance_mode("Dark")  # Modes: "System" (standard), "Dark", "Light"
ctk.set_default_color_theme("dark-blue")  # Themes: "blue" (standard), "green", "dark-blue"

class ImageGeneratorApp(ctk.CTk):
    def __init__(self):
        super().__init__()

        # Configures window
        self.default_window_width = 1200
        self.default_window_height = 800

        # Default values
        self.authorization_token = ""
        self.modelid = "CompVis/stable-diffusion-v1-4"
        self.device = "cuda"

        self.title("Image Generator")
        self.geometry(f"{self.default_window_width}x{self.default_window_height}")

        # Generates user interface
        self.create_widgets()

    def create_widgets(self):
        self.window_label = ctk.CTkLabel(self, text="Image Generator", font=ctk.CTkFont(size=30, weight="bold"), padx=50, pady=50, text_color="white")
        self.window_label.pack()

        self.prompt_label = ctk.CTkLabel(self, text="Prompt", font=ctk.CTkFont(family="Times New Roman", size=20, weight="bold"), text_color="white")
        self.prompt_label.pack()

        self.prompt_entry = ctk.CTkEntry(self, placeholder_text="Enter your prompt here", width=self.default_window_width-20, height=40)
        self.prompt_entry.pack(padx=20, pady=20)

        self.generate_button = ctk.CTkButton(master=self, text="Generate Image", width=self.default_window_width-50, height=40, fg_color="transparent", border_width=2, text_color="white", command=self.generate)
        self.generate_button.pack()

    def generate(self):
        text_prompt = self.prompt_entry.get()

        self.generate_button.configure(state="disabled")

        progress = ctk.CTkProgressBar(master=self, orientation='horizontal', mode='indeterminate')
        progress.pack()
        progress.start()

        pipeline = StableDiffusionPipeline.from_pretrained(self.modelid, revision="fp16", torch_dtype=torch.float16, use_auth_token=self.authorization_token)
        pipeline.to(self.device)

        with autocast():
            generated_image = pipeline(text_prompt, guidance_scale=8.5).images[0]
            generated_image.save('generated_image.png')

        progress.stop()
        progress.pack_forget()
        self.generate_button.configure(state="normal")

        # Display the generated image in Colab
        display(Image(filename='generated_image.png'))

import torch
from torch import autocast
from diffusers import StableDiffusionPipeline
import matplotlib.pyplot as plt

authorization_token = ""
modelid = "CompVis/stable-diffusion-v1-4"
device = "cuda"

pipe = StableDiffusionPipeline.from_pretrained(modelid, revision="fp16", torch_dtype=torch.float16, use_auth_token=authorization_token)

pipe.to(device)

with autocast(device):
  textprompt = str(input("Enter your prompt: "))

  image = pipe(textprompt, guidance_scale=8.5).images[0]

  imgplot = plt.imshow(image)

with autocast(device):
  textprompt = str(input("Enter your prompt: "))

  image = pipe(textprompt, guidance_scale=8.5).images[0]

  imgplot = plt.imshow(image)

with autocast(device):
  textprompt = str(input("Enter your prompt: "))

  image = pipe(textprompt, guidance_scale=8.5).images[0]

  imgplot = plt.imshow(image)

with autocast(device):
  textprompt = str(input("Enter your prompt: "))

  image = pipe(textprompt, guidance_scale=8.5).images[0]


  imgplot = plt.imshow(image)

with autocast(device):
  textprompt = str(input("Enter your prompt: "))

  image = pipe(textprompt, guidance_scale=8.5).images[0]

  imgplot = plt.imshow(image)

!pip install salesforce-lavis

import torch
from lavis.models import load_model_and_preprocess
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model, vis_processors, _ = load_model_and_preprocess(name="blip_caption", model_type="base_coco", is_eval=True, device=device)

with autocast(device):
  textprompt = str(input("Enter your prompt: "))

  image = pipe(textprompt, guidance_scale=8.5).images[0]

  imgplot = plt.imshow(image)

"""#SnapScore using Lavis Model

We have generated captions using Salesforce-Lavis for three examples and compared SnapScore for those obtained from our LSTM model

#eg1
"""

from google.colab import files
uploaded = files.upload()

# Import necessary libraries
from PIL import Image
import torch

# Load the image
image_path = "Apple and banana.png"
image = Image.open(image_path)

# Convert RGBA to RGB if necessary
if image.mode == 'RGBA':
    image = image.convert('RGB')

# Assuming 'vis_processors' and 'model' are defined and 'device' is set
# Preprocess the image
image = vis_processors["eval"](image).unsqueeze(0).to(device)

# Generate caption
caption = model.generate({"image": image})

# Print the generated caption
print(caption)

"""##BLEU"""

import nltk
nltk.download('punkt')

from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.tokenize import word_tokenize
# Example sentences
reference = "a bunch of bananas and fruits hanging on a tree"
candidate = "a bunch of bananas hanging from a tree"

# Tokenize the sentences
ref_tokens = [word_tokenize(reference)]
cand_tokens = word_tokenize(candidate)

# Smooth BLEU score calculation
smoothie = SmoothingFunction().method4  # Adjust the smoothing function as needed
scoreBLEU = sentence_bleu(ref_tokens, cand_tokens, smoothing_function=smoothie)
print(f"Smoothed BLEU Score: {scoreBLEU:.4f}")

"""##ROUGE"""

!pip install rouge

from rouge import Rouge

# Example sentences
reference = "a bunch of bananas and fruits hanging on a tree"
candidate = "a bunch of bananas hanging from a tree"

# Initialize Rouge
rouge = Rouge()

# Calculate scores
scores = rouge.get_scores(candidate, reference)
print(scores)

from rouge import Rouge

# Example sentences
reference = "a bunch of bananas and fruits hanging on a tree"
candidate = "a bunch of bananas hanging from a tree"

# Initialize Rouge
rouge = Rouge()

# Calculate scores
scores = rouge.get_scores(candidate, reference)[0]  # Access the first (and only) set of scores

# Define a smoothing function
def smooth_scores(scores, alpha=0.1):
    for key in scores:
        scores[key]['p'] = (scores[key]['p'] + alpha) / (1 + alpha)
        scores[key]['r'] = (scores[key]['r'] + alpha) / (1 + alpha)
        scores[key]['f'] = (scores[key]['f'] + alpha) / (1 + alpha)
    return scores

# Apply smoothing
smoothed_scores = smooth_scores(scores)

print(smoothed_scores)

average_f1 = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3
print("Average ROUGE F1 Score:", average_f1)

"""##METEOR"""

import nltk

# Download the WordNet data
nltk.download('wordnet')

# After downloading, you can continue with the METEOR score calculation
from nltk.translate.meteor_score import meteor_score

# Example sentences
reference = "a bunch of bananas and fruits hanging on a tree"
candidate = "a bunch of bananas hanging from a tree"

# Tokenize both the reference and hypothesis
reference_tokens = reference.split()  # Tokenize reference
hypothesis_tokens = candidate.split()  # Tokenize hypothesis

# Calculate METEOR score
METEORscore = meteor_score([reference_tokens], hypothesis_tokens)
print("METEOR Score:", METEORscore)

"""##cosine"""

!pip install scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Example texts
text1 = "a bunch of bananas and fruits hanging on a tree"
text2 = "a bunch of bananas hanging from a tree"

# Initialize a vectorizer
vectorizer = TfidfVectorizer()

# Vectorize the texts
tfidf = vectorizer.fit_transform([text1, text2])

# Calculate cosine similarity
cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]

print("Cosine Similarity:", cosine_sim)

"""#snapscore"""

weights = {
    'BLEU': 0.20,    # Lower weight due to focus on exact n-gram matches
    'ROUGE': 0.20,   # Similar reason as BLEU
    'METEOR': 0.25,  # Higher weight as it accounts for synonyms and structure
    'cosine': 0.35   # Highest weight, focusing on semantic similarity
}

scores = {
    'BLEU': 0.3328,      # Example BLEU score
    'ROUGE': 0.6969696924952652,    # Example ROUGE score
    'METEOR': 0.6861724281549355,   # Example METEOR score
    'cosine': 0.5727393584196196    # Example cosine similarity score
}

# Calculate the SNAP Score as a weighted sum of the scores
snap_score = sum(weights[metric] * scores[metric] for metric in weights)

print("SNAP Score:", snap_score)

"""#eg2"""

from google.colab import files
uploaded = files.upload()

"""##BLEU"""

# Import necessary libraries
from PIL import Image
import torch

# Load the image
image_path = "doctor.png"
image = Image.open(image_path)

# Convert RGBA to RGB if necessary
if image.mode == 'RGBA':
    image = image.convert('RGB')

# Assuming 'vis_processors' and 'model' are defined and 'device' is set
# Preprocess the image
image = vis_processors["eval"](image).unsqueeze(0).to(device)

# Generate caption
caption = model.generate({"image": image})

# Print the generated caption
print(caption)

import nltk
nltk.download('punkt')

from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.tokenize import word_tokenize
# Example sentences
reference = "a man wearing a suit and tie standing with a stethoscope"
candidate = "a man wearing a blue lab coat and a stethoscope"

# Tokenize the sentences
ref_tokens = [word_tokenize(reference)]
cand_tokens = word_tokenize(candidate)

# Smooth BLEU score calculation
smoothie = SmoothingFunction().method4  # Adjust the smoothing function as needed
scoreBLEU = sentence_bleu(ref_tokens, cand_tokens, smoothing_function=smoothie)
print(f"Smoothed BLEU Score: {scoreBLEU:.4f}")

"""##ROUGE"""

from rouge import Rouge

# Example sentences
reference = "a man wearing a suit and tie standing with a stethoscope"
candidate = "a man wearing a blue lab coat and a stethoscope"

# Initialize Rouge
rouge = Rouge()

# Calculate scores
scores = rouge.get_scores(candidate, reference)
print(scores)

from rouge import Rouge

# Example sentences
reference = "a man wearing a suit and tie standing with a stethoscope"
candidate = "a man wearing a blue lab coat and a stethoscope"

# Initialize Rouge
rouge = Rouge()

# Calculate scores
scores = rouge.get_scores(candidate, reference)[0]  # Access the first (and only) set of scores

# Define a smoothing function
def smooth_scores(scores, alpha=0.1):
    for key in scores:
        scores[key]['p'] = (scores[key]['p'] + alpha) / (1 + alpha)
        scores[key]['r'] = (scores[key]['r'] + alpha) / (1 + alpha)
        scores[key]['f'] = (scores[key]['f'] + alpha) / (1 + alpha)
    return scores

# Apply smoothing
smoothed_scores = smooth_scores(scores)

print(smoothed_scores)

average_f1 = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3
print("Average ROUGE F1 Score:", average_f1)

"""##METEOR"""

import nltk

# Download the WordNet data
nltk.download('wordnet')

# After downloading, you can continue with the METEOR score calculation
from nltk.translate.meteor_score import meteor_score

# Example sentences
reference = "a man wearing a suit and tie standing with a stethoscope"
candidate = "a man wearing a blue lab coat and a stethoscope"

# Tokenize both the reference and hypothesis
reference_tokens = reference.split()  # Tokenize reference
hypothesis_tokens = candidate.split()  # Tokenize hypothesis

# Calculate METEOR score
METEORscore = meteor_score([reference_tokens], hypothesis_tokens)
print("METEOR Score:", METEORscore)

"""##cosine"""

!pip install scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Example texts
text1 = "a man wearing a suit and tie standing with a stethoscope"
text2 = "a man wearing a blue lab coat and a stethoscope"

# Initialize a vectorizer
vectorizer = TfidfVectorizer()

# Vectorize the texts
tfidf = vectorizer.fit_transform([text1, text2])

# Calculate cosine similarity
cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]

print("Cosine Similarity:", cosine_sim)

"""#snapscore"""

weights = {
    'BLEU': 0.20,    # Lower weight due to focus on exact n-gram matches
    'ROUGE': 0.20,   # Similar reason as BLEU
    'METEOR': 0.25,  # Higher weight as it accounts for synonyms and structure
    'cosine': 0.35   # Highest weight, focusing on semantic similarity
}

scores = {
    'BLEU': 0.2938,      # Example BLEU score
    'ROUGE': 0.575007031776574,    # Example ROUGE score
    'METEOR': 0.616925669350309,   # Example METEOR score
    'cosine': 0.36802320875611494    # Example cosine similarity score
}

# Calculate the SNAP Score as a weighted sum of the scores
snap_score = sum(weights[metric] * scores[metric] for metric in weights)

print("SNAP Score:", snap_score)

"""##snap score for animal eating grass, detailed, 8k"""

from google.colab import files
uploaded = files.upload()

"""##BLEU"""

# Import necessary libraries
from PIL import Image
import torch

# Load the image
image_path = "anaimal_grass.png"
image = Image.open(image_path)

# Convert RGBA to RGB if necessary
if image.mode == 'RGBA':
    image = image.convert('RGB')

# Assuming 'vis_processors' and 'model' are defined and 'device' is set
# Preprocess the image
image = vis_processors["eval"](image).unsqueeze(0).to(device)

# Generate caption
caption = model.generate({"image": image})

# Print the generated caption
print(caption)

import nltk
nltk.download('punkt')

from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.tokenize import word_tokenize
# Example sentences
reference = "animal standing in the grass with its mouth open"
candidate = "a close up of a dog with its mouth open"

# Tokenize the sentences
ref_tokens = [word_tokenize(reference)]
cand_tokens = word_tokenize(candidate)

# Smooth BLEU score calculation
smoothie = SmoothingFunction().method4  # Adjust the smoothing function as needed
scoreBLEU = sentence_bleu(ref_tokens, cand_tokens, smoothing_function=smoothie)
print(f"Smoothed BLEU Score: {scoreBLEU:.4f}")

"""##ROUGE"""

from rouge import Rouge

# Example sentences
reference = "animal standing in the grass with its mouth open"
candidate = "a close up of a dog with its mouth open"

# Initialize Rouge
rouge = Rouge()

# Calculate scores
scores = rouge.get_scores(candidate, reference)
print(scores)

from rouge import Rouge

# Example sentences
reference = "animal standing in the grass with its mouth open"
candidate = "a close up of a dog with its mouth open"

# Initialize Rouge
rouge = Rouge()

# Calculate scores
scores = rouge.get_scores(candidate, reference)[0]  # Access the first (and only) set of scores

# Define a smoothing function
def smooth_scores(scores, alpha=0.1):
    for key in scores:
        scores[key]['p'] = (scores[key]['p'] + alpha) / (1 + alpha)
        scores[key]['r'] = (scores[key]['r'] + alpha) / (1 + alpha)
        scores[key]['f'] = (scores[key]['f'] + alpha) / (1 + alpha)
    return scores

# Apply smoothing
smoothed_scores = smooth_scores(scores)

print(smoothed_scores)

average_f1 = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3
print("Average ROUGE F1 Score:", average_f1)

"""##METEOR"""

import nltk

# Download the WordNet data
nltk.download('wordnet')

# After downloading, you can continue with the METEOR score calculation
from nltk.translate.meteor_score import meteor_score

# Example sentences
reference = "animal standing in the grass with its mouth open"
candidate = "a close up of a dog with its mouth open"

# Tokenize both the reference and hypothesis
reference_tokens = reference.split()  # Tokenize reference
hypothesis_tokens = candidate.split()  # Tokenize hypothesis

# Calculate METEOR score
METEORscore = meteor_score([reference_tokens], hypothesis_tokens)
print("METEOR Score:", METEORscore)

"""##cosine"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Example texts
text1 = "animal standing in the grass with its mouth open"
text2 = "a close up of a dog with its mouth open"

# Initialize a vectorizer
vectorizer = TfidfVectorizer()

# Vectorize the texts
tfidf = vectorizer.fit_transform([text1, text2])

# Calculate cosine similarity
cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]

print("Cosine Similarity:", cosine_sim)

"""#snapscore"""

weights = {
    'BLEU': 0.20,    # Lower weight due to focus on exact n-gram matches
    'ROUGE': 0.20,   # Similar reason as BLEU
    'METEOR': 0.25,  # Higher weight as it accounts for synonyms and structure
    'cosine': 0.35   # Highest weight, focusing on semantic similarity
}

scores = {
    'BLEU': 0.2627,      # Example BLEU score
    'ROUGE': 0.46722122738690247,    # Example ROUGE score
    'METEOR': 0.4361263736263736,   # Example METEOR score
    'cosine': 0.31125746752705374    # Example cosine similarity score
}

# Calculate the SNAP Score as a weighted sum of the scores
snap_score = sum(weights[metric] * scores[metric] for metric in weights)

print("SNAP Score:", snap_score)